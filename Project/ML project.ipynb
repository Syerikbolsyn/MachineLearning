{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valid-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "print( cv2.__version__)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bridal-border",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello:  ['Logan']\n",
      "hello:  ['Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm']\n",
      "hello:  ['Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Logan', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Magneto', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Mystique', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Professor X', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm', 'Storm']\n"
     ]
    }
   ],
   "source": [
    "train_images = []       \n",
    "train_labels = []\n",
    "shape = (256,256)  \n",
    "train_path = 'Heroes/'\n",
    "\n",
    "for filename in os.listdir(train_path):\n",
    "    if filename.split('.')[1] == 'jpg':\n",
    "        img = cv2.imread(train_path + filename)\n",
    "        window_name = 'image'\n",
    "#         cv2.imshow(window_name, img)\n",
    "#         cv2.waitKey(0)  \n",
    "#         cv2.destroyAllWindows()\n",
    "        # Spliting file names and storing the labels for image in list\n",
    "        train_labels.append(filename.split('_')[0])\n",
    "        print(\"hello: \" ,train_labels)\n",
    "        \n",
    "        # Resize all images to a specific shape\n",
    "        \n",
    "        img = cv2.resize(img, shape)\n",
    "        \n",
    "        train_images.append(img)\n",
    "\n",
    "# Converting labels into One Hot encoded sparse matrix\n",
    "train_labels = pd.get_dummies(train_labels).values\n",
    "\n",
    "# Converting train_images to array\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "# Splitting Training data into train and validation dataset\n",
    "x_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "medieval-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moving-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "shape = (256,256)\n",
    "test_path = 'test/'\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    if filename.split('.')[1] == 'jpg':\n",
    "        img = cv2.imread(os.path.join(test_path,filename))\n",
    "        \n",
    "        # Spliting file names and storing the labels for image in list\n",
    "        test_labels.append(filename.split('_')[0])\n",
    "        \n",
    "        # Resize all images to a specific shape\n",
    "        img = cv2.resize(img,shape)\n",
    "        \n",
    "        test_images.append(img)\n",
    "        \n",
    "# Converting test_images to array\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "configured-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "inclusive-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential model\n",
    "model= Sequential()\n",
    "model.add(Conv2D(kernel_size=(5,5), filters=32, activation='tanh', input_shape=(256,256,3,)))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(filters=30,kernel_size = (3,3),activation='tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(5,activation = 'softmax'))\n",
    "    \n",
    "model.compile(\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'],\n",
    "              optimizer='adam'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "provincial-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 252, 252, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 250, 250, 30)      8670      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 125, 125, 30)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 123, 123, 30)      8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 61, 61, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 59, 59, 30)        8130      \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 104430)            0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                2088620   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 2,116,377\n",
      "Trainable params: 2,116,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "separate-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36 samples, validate on 13 samples\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.5671 - acc: 0.3056 - val_loss: 1.6165 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.6070 - acc: 0.2778 - val_loss: 1.6177 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.6065 - acc: 0.2778 - val_loss: 1.6187 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 1.6062 - acc: 0.2778 - val_loss: 1.6198 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.6060 - acc: 0.2778 - val_loss: 1.6204 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.6056 - acc: 0.2778 - val_loss: 1.6215 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 1.6053 - acc: 0.2778 - val_loss: 1.6228 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 1.6049 - acc: 0.2778 - val_loss: 1.6234 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.6047 - acc: 0.2778 - val_loss: 1.6245 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.6044 - acc: 0.2778 - val_loss: 1.6258 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.6038 - acc: 0.2778 - val_loss: 1.6269 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 1.6035 - acc: 0.2778 - val_loss: 1.6279 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.6032 - acc: 0.2778 - val_loss: 1.6291 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 9s 264ms/step - loss: 1.6028 - acc: 0.2778 - val_loss: 1.6300 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.6025 - acc: 0.2778 - val_loss: 1.6307 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.6023 - acc: 0.2778 - val_loss: 1.6320 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 1.6020 - acc: 0.2778 - val_loss: 1.6330 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 1.6017 - acc: 0.2778 - val_loss: 1.6336 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 1.6015 - acc: 0.2778 - val_loss: 1.6342 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.6013 - acc: 0.2778 - val_loss: 1.6351 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 9s 257ms/step - loss: 1.6011 - acc: 0.2778 - val_loss: 1.6360 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 9s 244ms/step - loss: 1.6010 - acc: 0.2778 - val_loss: 1.6367 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.6008 - acc: 0.2778 - val_loss: 1.6375 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 9s 257ms/step - loss: 1.6006 - acc: 0.2778 - val_loss: 1.6382 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.6004 - acc: 0.2778 - val_loss: 1.6388 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 10s 265ms/step - loss: 1.6001 - acc: 0.2778 - val_loss: 1.6397 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 1.5999 - acc: 0.2778 - val_loss: 1.6411 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.5994 - acc: 0.2778 - val_loss: 1.6422 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.5993 - acc: 0.2778 - val_loss: 1.6436 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 1.5987 - acc: 0.2778 - val_loss: 1.6444 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.5985 - acc: 0.2778 - val_loss: 1.6455 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 1.5983 - acc: 0.2778 - val_loss: 1.6466 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 1.5981 - acc: 0.2778 - val_loss: 1.6478 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 1.5978 - acc: 0.2778 - val_loss: 1.6488 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.5977 - acc: 0.2778 - val_loss: 1.6503 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.5973 - acc: 0.2778 - val_loss: 1.6513 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.5970 - acc: 0.2778 - val_loss: 1.6523 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 1.5968 - acc: 0.2778 - val_loss: 1.6535 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 1.5965 - acc: 0.2778 - val_loss: 1.6543 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 10s 272ms/step - loss: 1.5964 - acc: 0.2778 - val_loss: 1.6556 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.5962 - acc: 0.2778 - val_loss: 1.6569 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 9s 249ms/step - loss: 1.5958 - acc: 0.2778 - val_loss: 1.6574 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.5956 - acc: 0.2778 - val_loss: 1.6582 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 9s 243ms/step - loss: 1.5955 - acc: 0.2778 - val_loss: 1.6593 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.5951 - acc: 0.2778 - val_loss: 1.6605 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 9s 242ms/step - loss: 1.5949 - acc: 0.2778 - val_loss: 1.6615 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 9s 257ms/step - loss: 1.5947 - acc: 0.2778 - val_loss: 1.6622 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 1.5945 - acc: 0.2778 - val_loss: 1.6629 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 1.5944 - acc: 0.2778 - val_loss: 1.6633 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 1.5943 - acc: 0.2778 - val_loss: 1.6643 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.5941 - acc: 0.2778 - val_loss: 1.6654 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.5939 - acc: 0.2778 - val_loss: 1.6658 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 1.5936 - acc: 0.2778 - val_loss: 1.6667 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 1.5936 - acc: 0.2778 - val_loss: 1.6681 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 9s 249ms/step - loss: 1.5932 - acc: 0.2778 - val_loss: 1.6692 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 9s 255ms/step - loss: 1.5930 - acc: 0.2778 - val_loss: 1.6695 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.5930 - acc: 0.2778 - val_loss: 1.6702 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 9s 244ms/step - loss: 1.5927 - acc: 0.2778 - val_loss: 1.6714 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 1.5925 - acc: 0.2778 - val_loss: 1.6725 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 10s 265ms/step - loss: 1.5922 - acc: 0.2778 - val_loss: 1.6738 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.5920 - acc: 0.2778 - val_loss: 1.6748 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 1.5919 - acc: 0.2778 - val_loss: 1.6752 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 1.5918 - acc: 0.2778 - val_loss: 1.6757 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.5918 - acc: 0.2778 - val_loss: 1.6765 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 9s 244ms/step - loss: 1.5916 - acc: 0.2778 - val_loss: 1.6772 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 1.5915 - acc: 0.2778 - val_loss: 1.6778 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.5915 - acc: 0.2778 - val_loss: 1.6787 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.5912 - acc: 0.2778 - val_loss: 1.6798 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 1.5912 - acc: 0.2778 - val_loss: 1.6809 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 1.5910 - acc: 0.2778 - val_loss: 1.6818 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 9s 257ms/step - loss: 1.5907 - acc: 0.2778 - val_loss: 1.6823 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 1.5906 - acc: 0.2778 - val_loss: 1.6833 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.5904 - acc: 0.2778 - val_loss: 1.6843 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 1.5903 - acc: 0.2778 - val_loss: 1.6854 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 1.5902 - acc: 0.2778 - val_loss: 1.6864 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 1.5900 - acc: 0.2778 - val_loss: 1.6875 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.5896 - acc: 0.2778 - val_loss: 1.6884 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 1.5896 - acc: 0.2778 - val_loss: 1.6895 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 9s 249ms/step - loss: 1.5895 - acc: 0.2778 - val_loss: 1.6905 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 1.5893 - acc: 0.2778 - val_loss: 1.6915 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 10s 291ms/step - loss: 1.5891 - acc: 0.2778 - val_loss: 1.6924 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 9s 255ms/step - loss: 1.5892 - acc: 0.2778 - val_loss: 1.6928 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 1.5891 - acc: 0.2778 - val_loss: 1.6936 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 1.5890 - acc: 0.2778 - val_loss: 1.6938 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.5888 - acc: 0.2778 - val_loss: 1.6946 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.5887 - acc: 0.2778 - val_loss: 1.6953 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.5887 - acc: 0.2778 - val_loss: 1.6962 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 9s 245ms/step - loss: 1.5886 - acc: 0.2778 - val_loss: 1.6973 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 1.5884 - acc: 0.2778 - val_loss: 1.6974 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 9s 236ms/step - loss: 1.5885 - acc: 0.2778 - val_loss: 1.6977 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 8s 234ms/step - loss: 1.5884 - acc: 0.2778 - val_loss: 1.6974 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 9s 242ms/step - loss: 1.5884 - acc: 0.2778 - val_loss: 1.6979 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 9s 241ms/step - loss: 1.5883 - acc: 0.2778 - val_loss: 1.6981 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 1.5882 - acc: 0.2778 - val_loss: 1.6987 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 1.5881 - acc: 0.2778 - val_loss: 1.6987 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.5881 - acc: 0.2778 - val_loss: 1.6990 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.5880 - acc: 0.2778 - val_loss: 1.6996 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 1.5879 - acc: 0.2778 - val_loss: 1.7003 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 1.5878 - acc: 0.2778 - val_loss: 1.7013 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 9s 243ms/step - loss: 1.5879 - acc: 0.2778 - val_loss: 1.7024 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=100,batch_size=5,validation_data=(x_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "sealed-machine",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_png' from 'matplotlib' (C:\\Anaconda\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2054\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswitch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mFigureCanvas\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m             \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m         \u001b[0mfmt\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mdetermine\u001b[0m \u001b[0ma\u001b[0m \u001b[0msuitable\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[0msaving\u001b[0m \u001b[0mto\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0meither\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0m_PNG\u001b[0m \u001b[0mspecification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m                 \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mwww\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mTR\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2003\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mREC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mPNG\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20031110\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;31m#11keywords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mpil_kwargs\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_png' from 'matplotlib' (C:\\Anaconda\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "considerable-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.1.3\n",
      "  Using cached matplotlib-3.1.3-cp37-cp37m-win_amd64.whl (9.1 MB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib==3.1.3) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib==3.1.3) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib==3.1.3) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib==3.1.3) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib==3.1.3) (2.4.0)\n",
      "Requirement already satisfied: six in c:\\anaconda\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib==3.1.3) (1.15.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==3.1.3) (52.0.0.post20210125)\n",
      "Installing collected packages: matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] Процесс не может получить доступ к файлу, так как этот файл занят другим процессом: 'C:\\\\Anaconda\\\\Anaconda3\\\\Lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\fonts\\\\ttf\\\\DejaVuSans.ttf'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib==3.1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "representative-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual :-  ['Logant', 'Logant', 'Logant', 'Logant']\n",
      "[[0.20378698 0.23802023 0.21257046 0.16512571 0.18049656]\n",
      " [0.20378698 0.23802023 0.21257046 0.16512571 0.18049656]\n",
      " [0.20378698 0.23802023 0.21257046 0.16512571 0.18049656]\n",
      " [0.20378698 0.23802023 0.21257046 0.16512571 0.18049656]]\n",
      "Predicted :-  Magneto\n"
     ]
    }
   ],
   "source": [
    "checkImage = test_images[0:5]\n",
    "checklabel = test_labels[0:4]\n",
    "\n",
    "predict = model.predict(np.array(checkImage))\n",
    "\n",
    "output = { 0:'Logan',1:'Magneto',2:'Mystique',3:'Professor', 4: 'Storm'}\n",
    "\n",
    "print(\"Actual :- \",checklabel)\n",
    "print(predict)\n",
    "print(\"Predicted :- \",output[np.argmax(predict)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "found-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list()\n",
    "for test_image, test_label in zip(test_images, test_labels):\n",
    "    predict = model.predict(np.absarray(test_image))\n",
    "    results.append(predict)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "meaningful-monitoring",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-0a1df294b701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-restriction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
